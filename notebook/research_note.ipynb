{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "import functools\n",
    "import operator\n",
    "import json\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, AIMessage, ToolMessage, HumanMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search engine\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# code executer for chart\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Utility\n",
    "* Agent의 응답을 Human Message로 변환하는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Agent Supervisor\n",
    "* 관리자 Agent는 필요에 따라 fuction calling을 출력할 것이며, 필요하지 않을 때는 finish를 출력하는 역할을 담당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 수 있는 fuctions\n",
    "members = [\"Researcher\", \"Coder\", \"Writer\"]\n",
    "\n",
    "# # supervisor의 system 프롬프트\n",
    "# system_prompt = (\n",
    "#     \"You are a supervisor tasked with managing a conversation between the\"\n",
    "#     \" following workers:  {members}. Given the following user request,\"\n",
    "#     \" respond with the worker to act next. Each worker will perform a\"\n",
    "#     \" task and respond with their results and status. When finished,\"\n",
    "#     \" respond with FINISH.\"\n",
    "# )\n",
    "\n",
    "system_prompt = (\n",
    "    \"당신은 고객이 보내준 연구 내용을 보고, 연구노트를 작성해 주는 에이전시의 관리자입니다.\"\n",
    "    \"에이전시는 연구노트 작성을 위해 다양한 작업자와 협업을 진행합니다.\"\n",
    "    \"작업자들 : {members}\"\n",
    "    \"Researcher 작업자는 연구 노트의 내용을 더 풍부하게 하기 위해, 필요한 논문이나 자료를 검색해주는 역할을 합니다. Researcher 작업자는 꼭 한번 이상 호출을 하세요.\"\n",
    "    \"Coder 작업자는 연구 내용에 특정 수치가 있거나 그래프가 필요한 경우, python 코드를 동작시켜 시각화를 해주는 역할을 합니다. 시각화가 필요없는 경우 호출하지 않아도 됩니다.\"\n",
    "    \"Writer 작업자는 각각의 작업자들이 수행한 결과를 최종적으로 종합하여 연구노트 형식에 맞게 작성해 주는 역할을 합니다. Researcher와 Coder 작업자들이 모두 작업을 완료하면 호출하시면 됩니다.\"\n",
    "    \"각각의 작업자들은 자신의 작업을 수행하고, 결과와 상태를 반환합니다.\"\n",
    "    \"고객이 연구 내용을 보내 주면, 필요한 작업자를 선택하여 작업자를 반환해 주십시오.\"\n",
    "    \"마지막에는 항상 Writer 작업자를 호출하시면 되며, Writer 작업자가 연구노트 작성을 완료하면 FINISH를 선택하여 종료합니다.\"\n",
    ")\n",
    "\n",
    "# Supervisor가 출력할 수 있는 options\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "# Supervisor의 출력 스키마 정의\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "# Supervisor의 전체 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"위 대화를 고려할 때, 다음 작업을 진행해야할 작업자는 누구인가요?\"\n",
    "            \"아니면 FINISH 해야할까요? 다음 중 하나를 선택해 주세요 : {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Supervisor 노드 정의\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = prompt | llm.with_structured_output(routeResponse)\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* State 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State 정의\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Research Node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_react_agent() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m research_system_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m당신은 고객이 보내준 연구 내용을 보고, 연구 노트에서 더 조사할 만한 요소를 조사해 주는 작업자 입니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m연구 내용과 관련하여 논문이나 자료를 검색하여, 연구 노트에 추가할 수 있는 정보를 찾아주세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m research_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[1;32m      8\u001b[0m     [\n\u001b[1;32m      9\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, research_system_prompt),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     ]\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m research_agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtavily_tool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresearch_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m research_node \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(agent_node, agent\u001b[38;5;241m=\u001b[39mresearch_agent, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResearcher\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/langgraph/lib/python3.11/site-packages/langgraph/_api/deprecation.py:80\u001b[0m, in \u001b[0;36mdeprecated_parameter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     73\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in function \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and will be removed in version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremoval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: create_react_agent() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "research_system_prompt = (\n",
    "    \"당신은 고객이 보내준 연구 내용을 보고, 연구 노트에서 더 조사할 만한 요소를 조사해 주는 작업자 입니다.\"\n",
    "    \"연구 내용과 관련하여 논문이나 자료를 검색하여, 연구 노트에 추가할 수 있는 정보를 찾아주세요.\"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "research_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", research_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"위 대화에서, 연구 내용과 관련하여 논문이나 자료를 검색하여, 연구 노트에 추가할 수 있는 정보를 찾아주세요.\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "research_agent = create_react_agent(llm, tools=[tavily_tool],research_prompt)\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Coder Node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_system_prompt = (\n",
    "    \"당신은 고객이 보내준 연구 내용을 보고, 연구 노트에서 시각화 할 수 있는 모든 것들을 시각화해 주는 작업자 입니다.\"\n",
    "    \"연구 내용에 기재된 수치나 그래프 등 시각화가 가능한 요소를 찾아, python 코드를 동작시켜 시각화를 해주세요.\"\n",
    "    \"최종적으로 시각화 한 사진을 다운로드 받을 수 있는 링크를 전달 해 주세요\"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "coder_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", research_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"연구 내용에 기재된 수치나 그래프 등 시각화가 가능한 요소를 찾아, python 코드를 동작시켜 시각화를 해주세요.\"\n",
    "            \"최종적으로 시각화 한 사진을 다운로드 받을 수 있는 링크를 전달 해 주세요\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "code_agent = create_react_agent(llm, tools=[python_repl_tool], prompt=coder_prompt)\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Writer Node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_system_prompt = (\n",
    "    \"당신은 고객이 보내준 연구 내용을 보고, 연구노트를 작성해 주는 에이전시의 작업자입니다.\"\n",
    "    \"Writer 역할을 담당하는 당신은, 고객의 연구 내용과 다른 작업의 작업 내용을 취합해 연구 노트 형식에 맞게 작성해야 합니다.\"\n",
    "    \"연구노트의 형식은 다음과 같습니다.\"\n",
    "    \"<연구 노트 형식>\"\n",
    "    \"1. '-음', '-함' 과 같이 음슴체로 작성해 주세요.\"\n",
    "    \"2. 각 작업자와 고객이 보내준 연구 내용을 기반하여 작성해 주세요.\"\n",
    "    \"3. 마크다운 언어로 작성해 주세요.\"\n",
    "    \"4. 한국어로 작성해 주세요.\"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", writer_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"위 대화를 취합하여, 최종 연구노트를 작성해 주세요\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LLM 정의\n",
    "writer_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def writer_agent(state):\n",
    "    writer_chain = writer_prompt | writer_llm\n",
    "    result = writer_chain.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [writer_chain.invoke(state)]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graph 정의 및 노드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7bc896ec2110>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"Writer\", writer_agent)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graph Edge 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 도구들은 다시 supervisor로 return 한다\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "# 시작은 supervisor로\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "# 그래프 빌드\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_content = \"\"\"\n",
    "모델이  학습되는  과정에서,  각  epoch 마다  정해진  metric 을  기록할  수  있도록 \n",
    "시스템을  구현  하였음.  웹  상에서  UI 로  쉽게  확인하기  위해, WandB 를 \n",
    "도입하였으며, DiceScore, DiceLoss 를  학습과  검증  과정에서  모두  기록해  보았음. \n",
    "CNN 계열의  Unet-3D 와  Vnet, Transformer 계열의  Unetr, Swin-Unetr  총  4 개의 \n",
    "모델을  학습시켜본  결과는  아래와  같음 \n",
    "Vnet 과  Swin-Unetr 의  모델이  Unet-3D 와  Unetr 에  비해  좋은  Dice Socre 를  가짐 \n",
    "Vnet   \n",
    "Dice Coefficient → 0.956 \n",
    "Swin-Unetr   \n",
    "Dice Coefficient → 0.956 \n",
    "Unet-3D   \n",
    "Dice Coefficient → 0.931 \n",
    "Unetr   \n",
    "Dice Coefficient → 0.891 \n",
    "수치적인  성능으로  만  봤을  때는  Swin-Unet 과  Vnet 이  가장  좋은  성능을 \n",
    "가졌지만,  이  두  모델에  대해서  시각화  하여  결과를  살펴  보았음. \n",
    "두  모델  모두  비슷하게  잘  예측하지만, Vent 은  가끔씩  예측영역이  잘게  쪼개지는 \n",
    "현상이  나타났음.  이에  반해, SwinUnetr 은  전체적으로  시각화  품질  상태가 \n",
    "양호해음.  때문에, SwinUnetr 을  다낭신  데이터에  한해  SOTA 모델이라  채택하여, \n",
    "해당  모델의  성능을  높여보는데  집중  하기로  함. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content='연구 결과에 따르면, Unet-3D, Vnet, Unetr, Swin-Unetr 네 가지 모델 중에서 Vnet과 Swin-Unetr가 가장 높은 Dice Coefficient를 기록했습니다. 두 모델 모두 0.956의 Dice Coefficient를 보였으며, 이는 Unet-3D(0.931)와 Unetr(0.891)에 비해 우수한 성능입니다.\\n\\n하지만 시각화 결과에서는 Vnet이 가끔 예측 영역이 잘게 쪼개지는 현상을 보였고, Swin-Unetr은 전체적으로 시각화 품질이 양호하여 더 나은 결과를 제공한 것으로 나타났습니다. 이러한 이유로, Swin-Unetr이 다낭신 데이터에 대한 SOTA(State-Of-The-Art) 모델로 채택되었으며, 연구팀은 Swin-Unetr의 성능을 더욱 향상시키는 데 집중하기로 결정했습니다.\\n\\nWandB를 활용하여 학습과 검증 과정에서 DiceScore와 DiceLoss를 기록하였고, 이를 통해 모델의 성능을 체계적으로 관리하고 분석할 수 있었습니다. 이 시스템이 모델 개발과 평가에 있어 유용한 도구로 작용했음을 알 수 있습니다.', additional_kwargs={}, response_metadata={}, name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Writer'}}\n",
      "----\n",
      "{'Writer': {'messages': [AIMessage(content='# 연구 노트\\n\\n1. 모델 학습 과정에서 각 epoch마다 정해진 metric을 기록할 수 있도록 시스템을 구현했음.  \\n2. 웹 상에서 UI로 쉽게 확인하기 위해 WandB를 도입하였으며, DiceScore와 DiceLoss를 학습과 검증 과정에서 모두 기록해 보았음.  \\n3. CNN 계열의 Unet-3D와 Vnet, Transformer 계열의 Unetr, Swin-Unetr 총 4개의 모델을 학습시켰음.  \\n4. Vnet과 Swin-Unetr의 모델이 Unet-3D와 Unetr에 비해 좋은 Dice Score를 기록했음.  \\n   - Vnet: Dice Coefficient → 0.956  \\n   - Swin-Unetr: Dice Coefficient → 0.956  \\n   - Unet-3D: Dice Coefficient → 0.931  \\n   - Unetr: Dice Coefficient → 0.891  \\n5. 수치적인 성능으로는 Swin-Unetr과 Vnet이 가장 좋았지만, 시각화 결과에서는 Swin-Unetr의 품질이 더 양호했음.  \\n6. Vnet은 가끔 예측 영역이 잘게 쪼개지는 현상이 있었으나, Swin-Unetr은 시각화 품질이 좋았음.  \\n7. Swin-Unetr을 다낭신 데이터에 대한 SOTA 모델로 채택하여 성능을 높이는 데 집중하기로 함.  \\n8. WandB를 활용하여 학습과 검증 과정에서의 성능을 체계적으로 관리하고 분석할 수 있었음.  ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 350, 'prompt_tokens': 901, 'total_tokens': 1251, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_159d8341cc', 'finish_reason': 'stop', 'logprobs': None}, id='run-1478c2f9-9f6b-4cff-ae1f-da3a7f232e0e-0', usage_metadata={'input_tokens': 901, 'output_tokens': 350, 'total_tokens': 1251, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Writer'}}\n",
      "----\n",
      "{'Writer': {'messages': [AIMessage(content='# 최종 연구 노트\\n\\n1. 모델 학습 과정에서 각 epoch마다 정해진 metric을 기록할 수 있도록 시스템을 구현했음.\\n2. 웹 상에서 UI로 쉽게 확인하기 위해 WandB를 도입하였으며, DiceScore와 DiceLoss를 학습과 검증 과정에서 모두 기록해 보았음.\\n3. CNN 계열의 Unet-3D와 Vnet, Transformer 계열의 Unetr, Swin-Unetr 총 4개의 모델을 학습시켰음.\\n4. Vnet과 Swin-Unetr의 모델이 Unet-3D와 Unetr에 비해 좋은 Dice Score를 기록했음.\\n   - Vnet: Dice Coefficient → 0.956\\n   - Swin-Unetr: Dice Coefficient → 0.956\\n   - Unet-3D: Dice Coefficient → 0.931\\n   - Unetr: Dice Coefficient → 0.891\\n5. 수치적인 성능으로는 Swin-Unetr과 Vnet이 가장 좋았지만, 시각화 결과에서는 Swin-Unetr의 품질이 더 양호했음.\\n6. Vnet은 가끔 예측 영역이 잘게 쪼개지는 현상이 있었으나, Swin-Unetr은 시각화 품질이 좋았음.\\n7. Swin-Unetr을 다낭신 데이터에 대한 SOTA 모델로 채택하여 성능을 높이는 데 집중하기로 함.\\n8. WandB를 활용하여 학습과 검증 과정에서의 성능을 체계적으로 관리하고 분석할 수 있었음.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 344, 'prompt_tokens': 1255, 'total_tokens': 1599, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_159d8341cc', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b4118a5-1fd6-404b-bdcd-2ce8021cf2f9-0', usage_metadata={'input_tokens': 1255, 'output_tokens': 344, 'total_tokens': 1599, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=f\"<연구 내용> {research_content}</연구 내용>\")]},\n",
    "    {\"recursion_limit\": 10},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
