{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "import functools\n",
    "import operator\n",
    "import json\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, AIMessage, ToolMessage, HumanMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search engine\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# code executer for chart\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Utility\n",
    "* Agent의 응답을 Human Message로 변환하는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Agent Supervisor\n",
    "* 관리자 Agent는 필요에 따라 fuction calling을 출력할 것이며, 필요하지 않을 때는 finish를 출력하는 역할을 담당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 수 있는 fuctions\n",
    "members = [\"Researcher\", \"Coder\"]\n",
    "\n",
    "# supervisor의 system 프롬프트\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "\n",
    "# Supervisor가 출력할 수 있는 options\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "# Supervisor의 출력 스키마 정의\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "# Supervisor의 전체 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Supervisor 노드 정의\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = prompt | llm.with_structured_output(routeResponse)\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* State 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State 정의\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Research Node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'functools.partial' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresearch_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is the capital of France\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'functools.partial' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "research_node.invoke(\"what is the capital of France\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Coder Node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graph 정의 및 노드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x763cc647c890>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graph Edge 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 도구들은 다시 supervisor로 return 한다\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "# 시작은 supervisor로\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "# 그래프 빌드\n",
    "graph = workflow.compile(\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content='3D segmentation is a computer vision task that involves dividing a 3D point cloud or 3D mesh into semantically meaningful parts or regions. This process is essential in various applications, such as medical imaging, autonomous driving, and augmented reality, where understanding the structure and components of a 3D environment is crucial. Techniques for 3D segmentation often involve deep learning models that can accurately segment objects and features in 3D data. There are numerous research papers, benchmarks, and datasets available that focus on improving the efficiency and accuracy of 3D segmentation methods.', additional_kwargs={}, response_metadata={}, name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"What is 3d segmentation? plz search it\")]},\n",
    "    {\"recursion_limit\": 50,\n",
    "     \"configurable\": {\"thread_id\": \"1\"}},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_values = graph.get_state({\"configurable\": {\"thread_id\": \"1\"}}).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3d segmentation? plz search it', additional_kwargs={}, response_metadata={}, id='caaab1b5-14f0-4507-bc48-a2354c4e9796'),\n",
       " HumanMessage(content='3D segmentation is a computer vision task that involves dividing a 3D point cloud or 3D mesh into semantically meaningful parts or regions. This process is essential in various applications, such as medical imaging, autonomous driving, and augmented reality, where understanding the structure and components of a 3D environment is crucial. Techniques for 3D segmentation often involve deep learning models that can accurately segment objects and features in 3D data. There are numerous research papers, benchmarks, and datasets available that focus on improving the efficiency and accuracy of 3D segmentation methods.', additional_kwargs={}, response_metadata={}, name='Researcher')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
